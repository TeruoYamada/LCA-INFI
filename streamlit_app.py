import cdsapi
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy.feature as cfeature
from matplotlib import animation
import streamlit as st
from datetime import datetime, timedelta
import os
import pandas as pd
import geopandas as gpd
import io
import requests
from matplotlib.patches import PathPatch
from matplotlib.path import Path
from sklearn.linear_model import LinearRegression
import matplotlib.dates as mdates
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from scipy import signal
from scipy.optimize import curve_fit
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√£o inicial da p√°gina
st.set_page_config(layout="wide", page_title="Visualizador de AOD - MS")

# ‚úÖ Carregar autentica√ß√£o a partir do secrets.toml
try:
    ads_url = st.secrets["ads"]["url"]
    ads_key = st.secrets["ads"]["key"]
    client = cdsapi.Client(url=ads_url, key=ads_key)
except Exception as e:
    st.error("‚ùå Erro ao carregar as credenciais do CDS API. Verifique seu secrets.toml.")
    st.stop()

# Fun√ß√£o para baixar shapefile dos munic√≠pios de MS (simplificado)
@st.cache_data
def load_ms_municipalities():
    try:
        # URL para um shapefile de munic√≠pios do MS (substitua pelo URL correto)
        # Este √© um exemplo - voc√™ precisar√° de um URL real para os dados
        url = "https://geoftp.ibge.gov.br/organizacao_do_territorio/malhas_territoriais/malhas_municipais/" + \
              "municipio_2022/UFs/MS/MS_Municipios_2022.zip"
        
        # Tentativa de carregar os dados
        try:
            gdf = gpd.read_file(url)
            return gdf
        except:
            # Fallback: criar geodataframe simplificado com alguns munic√≠pios
            # Isso √© apenas para demonstra√ß√£o se n√£o conseguir carregar o shapefile real
            data = {
                'NM_MUN': ['Campo Grande', 'Dourados', 'Tr√™s Lagoas', 'Corumb√°', 'Ponta Por√£'],
                'geometry': [
                    gpd.points_from_xy([-54.6201], [-20.4697])[0].buffer(0.2),
                    gpd.points_from_xy([-54.812], [-22.2231])[0].buffer(0.2),
                    gpd.points_from_xy([-51.7005], [-20.7849])[0].buffer(0.2),
                    gpd.points_from_xy([-57.651], [-19.0082])[0].buffer(0.2),
                    gpd.points_from_xy([-55.7271], [-22.5334])[0].buffer(0.2)
                ]
            }
            gdf = gpd.GeoDataFrame(data, crs="EPSG:4326")
            return gdf
    except Exception as e:
        st.warning(f"N√£o foi poss√≠vel carregar os shapes dos munic√≠pios: {str(e)}")
        # Retornar DataFrame vazio com estrutura esperada
        return gpd.GeoDataFrame(columns=['NM_MUN', 'geometry'], crs="EPSG:4326")

# üéØ Lista completa dos munic√≠pios de MS com coordenadas
# Expandida para incluir todos os 79 munic√≠pios do MS
cities = {
    "√Ågua Clara": [-20.4453, -52.8792],
    "Alcin√≥polis": [-18.3255, -53.7042],
    "Amambai": [-23.1058, -55.2253],
    "Anast√°cio": [-20.4823, -55.8104],
    "Anauril√¢ndia": [-22.1852, -52.7191],
    "Ang√©lica": [-22.1527, -53.7708],
    "Ant√¥nio Jo√£o": [-22.1927, -55.9511],
    "Aparecida do Taboado": [-20.0873, -51.0961],
    "Aquidauana": [-20.4697, -55.7868],
    "Aral Moreira": [-22.9384, -55.6331],
    "Bandeirantes": [-19.9279, -54.3581],
    "Bataguassu": [-21.7156, -52.4233],
    "Bataypor√£": [-22.2947, -53.2705],
    "Bela Vista": [-22.1073, -56.5263],
    "Bodoquena": [-20.5372, -56.7138],
    "Bonito": [-21.1261, -56.4836],
    "Brasil√¢ndia": [-21.2544, -52.0382],
    "Caarap√≥": [-22.6368, -54.8209],
    "Camapu√£": [-19.5302, -54.0431],
    "Campo Grande": [-20.4697, -54.6201],
    "Caracol": [-22.0112, -57.0278],
    "Cassil√¢ndia": [-19.1179, -51.7308],
    "Chapad√£o do Sul": [-18.7908, -52.6260],
    "Corguinho": [-19.8243, -54.8281],
    "Coronel Sapucaia": [-23.2724, -55.5278],
    "Corumb√°": [-19.0082, -57.651],
    "Costa Rica": [-18.5432, -53.1287],
    "Coxim": [-18.5013, -54.7603],
    "Deod√°polis": [-22.2789, -54.1583],
    "Dois Irm√£os do Buriti": [-20.6845, -55.2915],
    "Douradina": [-22.0430, -54.6158],
    "Dourados": [-22.2231, -54.812],
    "Eldorado": [-23.7868, -54.2836],
    "F√°tima do Sul": [-22.3789, -54.5131],
    "Figueir√£o": [-18.6782, -53.6380],
    "Gl√≥ria de Dourados": [-22.4136, -54.2336],
    "Guia Lopes da Laguna": [-21.4583, -56.1117],
    "Iguatemi": [-23.6835, -54.5635],
    "Inoc√™ncia": [-19.7276, -51.9281],
    "Itapor√£": [-22.0750, -54.7933],
    "Itaquira√≠": [-23.4779, -54.1873],
    "Ivinhema": [-22.3046, -53.8185],
    "Japor√£": [-23.8903, -54.4059],
    "Jaraguari": [-20.1386, -54.3996],
    "Jardim": [-21.4799, -56.1489],
    "Jate√≠": [-22.4806, -54.3078],
    "Juti": [-22.8596, -54.6060],
    "Lad√°rio": [-19.0090, -57.5973],
    "Laguna Carap√£": [-22.5448, -55.1502],
    "Maracaju": [-21.6105, -55.1695],
    "Miranda": [-20.2407, -56.3780],
    "Mundo Novo": [-23.9355, -54.2807],
    "Navira√≠": [-23.0618, -54.1995],
    "Nioaque": [-21.1419, -55.8296],
    "Nova Alvorada do Sul": [-21.4657, -54.3825],
    "Nova Andradina": [-22.2332, -53.3437],
    "Novo Horizonte do Sul": [-22.6693, -53.8601],
    "Para√≠so das √Åguas": [-19.0218, -53.0116],
    "Parana√≠ba": [-19.6746, -51.1909],
    "Paranhos": [-23.8905, -55.4289],
    "Pedro Gomes": [-18.0996, -54.5507],
    "Ponta Por√£": [-22.5334, -55.7271],
    "Porto Murtinho": [-21.6981, -57.8825],
    "Ribas do Rio Pardo": [-20.4432, -53.7588],
    "Rio Brilhante": [-21.8033, -54.5427],
    "Rio Negro": [-19.4473, -54.9859],
    "Rio Verde de Mato Grosso": [-18.9249, -54.8434],
    "Rochedo": [-19.9566, -54.8940],
    "Santa Rita do Pardo": [-21.3016, -52.8333],
    "S√£o Gabriel do Oeste": [-19.3950, -54.5507],
    "Selv√≠ria": [-20.3637, -51.4192],
    "Sete Quedas": [-23.9710, -55.0396],
    "Sidrol√¢ndia": [-20.9302, -54.9692],
    "Sonora": [-17.5698, -54.7551],
    "Tacuru": [-23.6361, -55.0141],
    "Taquarussu": [-22.4898, -53.3519],
    "Terenos": [-20.4378, -54.8647],
    "Tr√™s Lagoas": [-20.7849, -51.7005],
    "Vicentina": [-22.4098, -54.4415]
}

# T√≠tulos e introdu√ß√£o
st.title("üåÄ Monitoramento e Previs√£o de AOD (550nm) - Mato Grosso do Sul")
st.markdown("""
Este aplicativo permite visualizar e analisar dados de Profundidade √ìptica de Aeross√≥is (AOD) a 550nm 
para munic√≠pios de Mato Grosso do Sul. Os dados s√£o obtidos em tempo real do CAMS (Copernicus Atmosphere 
Monitoring Service).
""")

# Fun√ß√£o para extrair valores de AOD para um ponto espec√≠fico
def extract_point_timeseries(ds, lat, lon, var_name='aod550'):
    """Extrai s√©rie temporal de um ponto espec√≠fico do dataset."""
    lat_idx = np.abs(ds.latitude.values - lat).argmin()
    lon_idx = np.abs(ds.longitude.values - lon).argmin()
    
    # Identificar as dimens√µes temporais
    time_dims = [dim for dim in ds[var_name].dims if 'time' in dim or 'forecast' in dim]
    
    # Criar dataframe para armazenar valores por tempo
    times = []
    values = []
    
    # Se tivermos forecast_reference_time e forecast_period
    if 'forecast_reference_time' in ds[var_name].dims and 'forecast_period' in ds[var_name].dims:
        for t_idx, ref_time in enumerate(ds.forecast_reference_time.values):
            for p_idx, period in enumerate(ds.forecast_period.values):
                try:
                    value = float(ds[var_name].isel(
                        forecast_reference_time=t_idx, 
                        forecast_period=p_idx,
                        latitude=lat_idx, 
                        longitude=lon_idx
                    ).values)
                    
                    # Calcular o tempo real somando o per√≠odo √† refer√™ncia
                    actual_time = pd.to_datetime(ref_time) + pd.to_timedelta(period, unit='h')
                    times.append(actual_time)
                    values.append(value)
                except:
                    continue
def moving_average_forecast(df, window=3, days=5):
    """Previs√£o usando m√©dia m√≥vel simples."""
    if len(df) < window:
        return pd.DataFrame(columns=['time', 'aod', 'type', 'method'])
    
    # Calcular m√©dia m√≥vel dos √∫ltimos valores
    last_values = df['aod'].tail(window).mean()
    
    # Gerar pontos futuros
    last_time = df['time'].max()
    future_times = [last_time + timedelta(hours=i*6) for i in range(1, days*4+1)]
    
    # Usar m√©dia m√≥vel como previs√£o (assumindo tend√™ncia est√°vel)
    future_aod = [last_values] * len(future_times)
    
    return pd.DataFrame({
        'time': future_times,
        'aod': future_aod,
        'type': 'forecast',
        'method': 'moving_average'
    })
 def exponential_smoothing_forecast(df, alpha=0.3, days=5):
    """Previs√£o usando suaviza√ß√£o exponencial."""
    if len(df) < 2:
        return pd.DataFrame(columns=['time', 'aod', 'type', 'method'])
    
    # Aplicar suaviza√ß√£o exponencial
    values = df['aod'].values
    smoothed = [values[0]]
    
    for i in range(1, len(values)):
        smoothed.append(alpha * values[i] + (1 - alpha) * smoothed[-1])
    
    # Usar √∫ltimo valor suavizado como previs√£o
    last_smoothed = smoothed[-1]
    
    # Gerar pontos futuros
    last_time = df['time'].max()
    future_times = [last_time + timedelta(hours=i*6) for i in range(1, days*4+1)]
    future_aod = [last_smoothed] * len(future_times)
    
    return pd.DataFrame({
        'time': future_times,
        'aod': future_aod,
        'type': 'forecast',
        'method': 'exponential_smoothing'
    })
def polynomial_forecast(df, degree=2, days=5):
    """Previs√£o usando ajuste polinomial."""
    if len(df) < degree + 1:
        return pd.DataFrame(columns=['time', 'aod', 'type', 'method'])
    
    # Preparar dados
    df_work = df.copy()
    df_work['time_numeric'] = (df_work['time'] - df_work['time'].min()).dt.total_seconds()
    
    # Ajustar polin√¥mio
    coeffs = np.polyfit(df_work['time_numeric'], df_work['aod'], degree)
    poly_func = np.poly1d(coeffs)
    
    # Gerar pontos futuros
    last_time = df['time'].max()
    future_times = [last_time + timedelta(hours=i*6) for i in range(1, days*4+1)]
    
    # Calcular valores futuros
    future_time_numeric = [(t - df['time'].min()).total_seconds() for t in future_times]
    future_aod = poly_func(future_time_numeric)
    
    # Limitar valores negativos
    future_aod = np.maximum(future_aod, 0)
    
    return pd.DataFrame({
        'time': future_times,
        'aod': future_aod,
        'type': 'forecast',
        'method': f'polynomial_deg{degree}'
    })
def seasonal_decomposition_forecast(df, days=5):
    """Previs√£o baseada em decomposi√ß√£o sazonal simplificada."""
    if len(df) < 8:  # Precisa de pelo menos 8 pontos para detectar padr√µes
        return pd.DataFrame(columns=['time', 'aod', 'type', 'method'])
    
    # Calcular tend√™ncia simples (regress√£o linear)
    df_work = df.copy()
    df_work['time_numeric'] = (df_work['time'] - df_work['time'].min()).dt.total_seconds()
    
    # Tend√™ncia linear
    slope, intercept = np.polyfit(df_work['time_numeric'], df_work['aod'], 1)
    trend = slope * df_work['time_numeric'] + intercept
    
    # Componente sazonal (ciclo di√°rio simplificado)
    df_work['hour'] = df_work['time'].dt.hour
    hourly_means = df_work.groupby('hour')['aod'].mean()
    
    # Gerar pontos futuros
    last_time = df['time'].max()
    future_times = [last_time + timedelta(hours=i*6) for i in range(1, days*4+1)]
    
    future_aod = []
    for future_time in future_times:
        # Calcular tend√™ncia futura
        future_time_numeric = (future_time - df['time'].min()).total_seconds()
        future_trend = slope * future_time_numeric + intercept
        
        # Adicionar componente sazonal
        hour = future_time.hour
        if hour in hourly_means.index:
            seasonal_component = hourly_means[hour] - df['aod'].mean()
        else:
            seasonal_component = 0
        
        predicted_value = future_trend + seasonal_component
        future_aod.append(max(0, predicted_value))
    
    return pd.DataFrame({
        'time': future_times,
        'aod': future_aod,
        'type': 'forecast',
        'method': 'seasonal_decomposition'
    })
def random_forest_forecast(df, days=5):
    """Previs√£o usando Random Forest com features temporais."""
    if len(df) < 5:
        return pd.DataFrame(columns=['time', 'aod', 'type', 'method'])
    
    # Criar features temporais
    df_work = df.copy()
    df_work['hour'] = df_work['time'].dt.hour
    df_work['day_of_year'] = df_work['time'].dt.dayofyear
    df_work['time_numeric'] = (df_work['time'] - df_work['time'].min()).dt.total_seconds()
    
    # Criar features de lag (valores anteriores)
    for lag in [1, 2, 3]:
        df_work[f'aod_lag_{lag}'] = df_work['aod'].shift(lag)
    
    # Remover linhas com NaN
    df_clean = df_work.dropna()
    
    if len(df_clean) < 3:
        return pd.DataFrame(columns=['time', 'aod', 'type', 'method'])
    
    # Preparar dados para treinamento
    feature_cols = ['hour', 'day_of_year', 'time_numeric'] + [f'aod_lag_{i}' for i in [1, 2, 3]]
    X = df_clean[feature_cols].values
    y = df_clean['aod'].values
    
    # Treinar modelo
    rf = RandomForestRegressor(n_estimators=50, random_state=42)
    rf.fit(X, y)
    
    # Gerar previs√µes futuras
    last_time = df['time'].max()
    future_times = [last_time + timedelta(hours=i*6) for i in range(1, days*4+1)]
    
    future_aod = []
    last_values = df['aod'].tail(3).values  # √öltimos 3 valores para lags
    
    for i, future_time in enumerate(future_times):
        # Criar features para o ponto futuro
        hour = future_time.hour
        day_of_year = future_time.timetuple().tm_yday
        time_numeric = (future_time - df['time'].min()).total_seconds()
        
        # Usar valores anteriores como lags
        if i == 0:
            lags = last_values
        elif i == 1:
            lags = np.append(last_values[1:], [future_aod[0]])
        elif i == 2:
            lags = np.append(last_values[2:], future_aod[:2])
        else:
            lags = future_aod[i-3:i]
        
        # Garantir que temos 3 lags
        if len(lags) < 3:
            lags = np.pad(lags, (3-len(lags), 0), mode='edge')
        
        features = np.array([[hour, day_of_year, time_numeric] + lags[-3:].tolist()])
        prediction = rf.predict(features)[0]
        future_aod.append(max(0, prediction))
    
    return pd.DataFrame({
        'time': future_times,
        'aod': future_aod,
        'type': 'forecast',
        'method': 'random_forest'
    })
def ensemble_forecast(df, days=5):
    """Previs√£o ensemble combinando m√∫ltiplos m√©todos."""
    methods = [
        moving_average_forecast,
        exponential_smoothing_forecast,
        lambda x, d: polynomial_forecast(x, degree=2, days=d),
        seasonal_decomposition_forecast,
        random_forest_forecast
    ]
    
    forecasts = []
    weights = [0.15, 0.2, 0.2, 0.25, 0.2]  # Pesos para cada m√©todo
    
    # Gerar previs√µes de todos os m√©todos
    for method in methods:
        try:
            forecast = method(df, days)
            if not forecast.empty:
                forecasts.append(forecast['aod'].values)
        except:
            continue
    
    if not forecasts:
        return pd.DataFrame(columns=['time', 'aod', 'type', 'method'])
    
    # Calcular m√©dia ponderada
    forecasts_array = np.array(forecasts)
    if len(forecasts) != len(weights):
        # Usar pesos iguais se n√∫mero de m√©todos for diferente
        weights = [1/len(forecasts)] * len(forecasts)
    
    ensemble_aod = np.average(forecasts_array, axis=0, weights=weights[:len(forecasts)])
    
    # Gerar pontos futuros
    last_time = df['time'].max()
    future_times = [last_time + timedelta(hours=i*6) for i in range(1, days*4+1)]
    
    return pd.DataFrame({
        'time': future_times,
        'aod': ensemble_aod,
        'type': 'forecast',
        'method': 'ensemble'
    })
    # Caso tenha apenas uma dimens√£o de tempo
    elif any(dim in ds[var_name].dims for dim in ['time', 'forecast_reference_time']):
        time_dim = next(dim for dim in ds[var_name].dims if dim in ['time', 'forecast_reference_time'])
        for t_idx in range(len(ds[time_dim])):
            try:
                value = float(ds[var_name].isel({
                    time_dim: t_idx,
                    'latitude': lat_idx,
                    'longitude': lon_idx
                }).values)
                times.append(pd.to_datetime(ds[time_dim].isel({time_dim: t_idx}).values))
                values.append(value)
            except:
                continue
    
    # Criar DataFrame
    if times and values:
        df = pd.DataFrame({'time': times, 'aod': values})
        df = df.sort_values('time').reset_index(drop=True)
        return df
    else:
        return pd.DataFrame(columns=['time', 'aod'])

# Fun√ß√£o para prever valores futuros de AOD
def predict_future_aod_advanced(df, method='ensemble', days=5):
    """Gera previs√£o usando o m√©todo especificado."""
    if len(df) < 2:
        return pd.DataFrame(columns=['time', 'aod', 'type', 'method'])
    
    # Adicionar dados hist√≥ricos
    df_hist = df.copy()
    df_hist['type'] = 'historical'
    df_hist['method'] = 'observed'
    
    # Escolher m√©todo de previs√£o
    if method == 'linear_regression':
        # Regress√£o linear (m√©todo original)
        df_hist['time_numeric'] = (df_hist['time'] - df_hist['time'].min()).dt.total_seconds()
        X = df_hist['time_numeric'].values.reshape(-1, 1)
        y = df_hist['aod'].values
        model = LinearRegression()
        model.fit(X, y)
        
        last_time = df_hist['time'].max()
        future_times = [last_time + timedelta(hours=i*6) for i in range(1, days*4+1)]
        future_time_numeric = [(t - df_hist['time'].min()).total_seconds() for t in future_times]
        future_aod = model.predict(np.array(future_time_numeric).reshape(-1, 1))
        future_aod = np.maximum(future_aod, 0)
        
        df_pred = pd.DataFrame({
            'time': future_times,
            'aod': future_aod,
            'type': 'forecast',
            'method': 'linear_regression'
        })
    
    elif method == 'moving_average':
        df_pred = moving_average_forecast(df, days=days)
    elif method == 'exponential_smoothing':
        df_pred = exponential_smoothing_forecast(df, days=days)
    elif method == 'polynomial':
        df_pred = polynomial_forecast(df, degree=2, days=days)
    elif method == 'seasonal':
        df_pred = seasonal_decomposition_forecast(df, days=days)
    elif method == 'random_forest':
        df_pred = random_forest_forecast(df, days=days)
    elif method == 'ensemble':
        df_pred = ensemble_forecast(df, days=days)
    else:
        # Default para ensemble
        df_pred = ensemble_forecast(df, days=days)
    
    # Combinar hist√≥rico e previs√£o
    result = pd.concat([df_hist[['time', 'aod', 'type', 'method']], df_pred], ignore_index=True)
    return result
def compare_forecast_methods(df, days=5):
    """Compara diferentes m√©todos de previs√£o."""
    methods = {
        'Regress√£o Linear': 'linear_regression',
        'M√©dia M√≥vel': 'moving_average',
        'Suaviza√ß√£o Exponencial': 'exponential_smoothing',
        'Polinomial': 'polynomial',
        'Decomposi√ß√£o Sazonal': 'seasonal',
        'Random Forest': 'random_forest',
        'Ensemble': 'ensemble'
    }
    
    forecasts = {}
    
    for name, method in methods.items():
        try:
            forecast = predict_future_aod_advanced(df, method=method, days=days)
            forecasts[name] = forecast
        except Exception as e:
            st.warning(f"Erro no m√©todo {name}: {str(e)}")
            continue
    
    return forecasts

# NOVA FUN√á√ÉO: Analisar AOD para todas as cidades e gerar tabela de alertas
def analyze_all_cities(ds, aod_var, cities_dict):
    """Analisa os valores de AOD para todas as cidades e retorna as 20 mais cr√≠ticas."""
    cities_results = []
    
    # Para cada cidade, extrair s√©rie temporal e determinar valor m√°ximo previsto
    with st.spinner(f"Analisando AOD para todos os munic√≠pios de MS... (0/{len(cities_dict)})"):
        for i, (city_name, coords) in enumerate(cities_dict.items()):
            # Atualize o spinner a cada 10 cidades para n√£o sobrecarregar a interface
            if i % 10 == 0:
                st.spinner(f"Analisando AOD para todos os munic√≠pios de MS... ({i}/{len(cities_dict)})")
            
            lat, lon = coords
            
            # Extrair s√©rie temporal para a cidade
            df_timeseries = extract_point_timeseries(ds, lat, lon, var_name=aod_var)
            
            if not df_timeseries.empty:
                # Gerar previs√£o
                df_forecast = predict_future_aod(df_timeseries, days=5)
                
                # Filtrar apenas dados de previs√£o
                forecast_only = df_forecast[df_forecast['type'] == 'forecast']
                
                if not forecast_only.empty:
                    # Obter valor m√°ximo previsto e quando ocorrer√°
                    max_aod = forecast_only['aod'].max()
                    max_day = forecast_only.loc[forecast_only['aod'].idxmax(), 'time']
                    
                    # Categorizar n√≠vel de polui√ß√£o
                    pollution_level = "Baixo"
                    if max_aod >= 0.5:
                        pollution_level = "Muito Alto"
                    elif max_aod >= 0.2:
                        pollution_level = "Alto"
                    elif max_aod >= 0.1:
                        pollution_level = "Moderado"
                    
                    # Adicionar resultado √† lista
                    cities_results.append({
                        'cidade': city_name,
                        'aod_max': max_aod,
                        'data_max': max_day,
                        'nivel': pollution_level
                    })
    
    # Criar DataFrame com os resultados
    if cities_results:
        df_results = pd.DataFrame(cities_results)
        
        # Ordenar por AOD m√°ximo (decrescente)
        df_results = df_results.sort_values('aod_max', ascending=False).reset_index(drop=True)
        
        # Formatar o DataFrame para exibi√ß√£o
        df_results['aod_max'] = df_results['aod_max'].round(3)
        df_results['data_max'] = df_results['data_max'].dt.strftime('%d/%m/%Y %H:%M')
        
        return df_results
    else:
        return pd.DataFrame(columns=['cidade', 'aod_max', 'data_max', 'nivel'])

# Fun√ß√£o principal para gerar an√°lise de AOD
def generate_aod_analysis():
    dataset = "cams-global-atmospheric-composition-forecasts"
    
    # Format dates and times correctly for ADS API
    start_date_str = start_date.strftime('%Y-%m-%d')
    end_date_str = end_date.strftime('%Y-%m-%d')
    
    # Create list of hours in the correct format
    hours = []
    current_hour = start_hour
    while True:
        hours.append(f"{current_hour:02d}:00")
        if current_hour == end_hour:
            break
        current_hour = (current_hour + 3) % 24
        if current_hour == start_hour:  # Evitar loop infinito
            break
    
    # Se n√£o tivermos horas definidas, usar padr√£o
    if not hours:
        hours = ['00:00', '03:00', '06:00', '09:00', '12:00', '15:00', '18:00', '21:00']
    
    # Preparar request para API
    request = {
        'variable': ['total_aerosol_optical_depth_550nm'],
        'date': f'{start_date_str}/{end_date_str}',
        'time': hours,
        'leadtime_hour': ['0', '24', '48', '72', '96', '120'],  # Incluir previs√µes de at√© 5 dias
        'type': ['forecast'],
        'format': 'netcdf',
        'area': [lat_center + map_width/2, lon_center - map_width/2, 
                lat_center - map_width/2, lon_center + map_width/2]
    }
    
    filename = f'AOD550_{city}_{start_date}_to_{end_date}.nc'
    
    try:
        with st.spinner('üì• Baixando dados do CAMS...'):
            client.retrieve(dataset, request).download(filename)
        
        ds = xr.open_dataset(filename)
        
        # Verificar vari√°veis dispon√≠veis
        variable_names = list(ds.data_vars)
        st.write(f"Vari√°veis dispon√≠veis: {variable_names}")
        
        # Usar a vari√°vel 'aod550' encontrada nos dados
        aod_var = next((var for var in variable_names if 'aod' in var.lower()), variable_names[0])
        
        st.write(f"Usando vari√°vel: {aod_var}")
        da = ds[aod_var]
        
        # Verificar dimens√µes
        st.write(f"Dimens√µes: {da.dims}")
        
        # Identificar dimens√µes temporais
        time_dims = [dim for dim in da.dims if 'time' in dim or 'forecast' in dim]
        
        if not time_dims:
            st.error("N√£o foi poss√≠vel identificar dimens√£o temporal nos dados.")
            return None
        
        # Extrair s√©rie temporal para o ponto central (cidade selecionada)
        with st.spinner("Extraindo s√©rie temporal para o munic√≠pio..."):
            df_timeseries = extract_point_timeseries(ds, lat_center, lon_center, var_name=aod_var)
        
        if df_timeseries.empty:
            st.error("N√£o foi poss√≠vel extrair s√©rie temporal para este local.")
            return None
        
        # Gerar previs√£o para os pr√≥ximos dias
        with st.spinner("Gerando previs√£o de AOD..."):
            df_forecast = predict_future_aod(df_timeseries, days=5)  # Aumentado para 5 dias
        
        # Encontrar o munic√≠pio no geodataframe
        municipality_shape = None
        if not ms_shapes.empty:
            city_shape = ms_shapes[ms_shapes['NM_MUN'] == city]
            if not city_shape.empty:
                municipality_shape = city_shape.iloc[0].geometry
        
        # --- Cria√ß√£o da anima√ß√£o ---
        # Identificar frames dispon√≠veis
        if 'forecast_reference_time' in da.dims:
            time_dim = 'forecast_reference_time'
            frames = len(da[time_dim])
        else:
            time_dim = time_dims[0]
            frames = len(da[time_dim])
        
        st.write(f"‚úÖ Total de frames dispon√≠veis: {frames}")
        
        if frames < 1:
            st.error("Erro: Dados insuficientes para anima√ß√£o.")
            return None
        
        # Determinar range de cores
        vmin, vmax = float(da.min().values), float(da.max().values)
        vmin = max(0, vmin - 0.05)
        vmax = min(2, vmax + 0.05)  # AOD geralmente n√£o ultrapassa 2
        
        # Criar figura
        fig = plt.figure(figsize=(12, 8))
        ax = plt.subplot(1, 1, 1, projection=ccrs.PlateCarree())
        
        # Adicionar features b√°sicas
        ax.coastlines(resolution='10m')
        ax.add_feature(cfeature.BORDERS.with_scale('10m'), linestyle=':')
        ax.add_feature(cfeature.STATES.with_scale('10m'), linestyle=':')
        
        # Adicionar grid
        gl = ax.gridlines(draw_labels=True, linewidth=1, color='gray', alpha=0.5, linestyle='--')
        gl.top_labels = False
        gl.right_labels = False
        
        # Definir extens√£o do mapa
        ax.set_extent([lon_center - map_width/2, lon_center + map_width/2, 
                    lat_center - map_width/2, lat_center + map_width/2], 
                   crs=ccrs.PlateCarree())
        
        # Obter primeiro frame para inicializar
        first_frame_data = None
        first_frame_time = None
        
        if 'forecast_period' in da.dims and 'forecast_reference_time' in da.dims:
            if len(da.forecast_period) > 0 and len(da.forecast_reference_time) > 0:
                first_frame_data = da.isel(forecast_period=0, forecast_reference_time=0).values
                first_frame_time = pd.to_datetime(ds.forecast_reference_time.values[0])
            else:
                first_frame_coords = {dim: 0 for dim in da.dims if len(da[dim]) > 0}
                first_frame_data = da.isel(**first_frame_coords).values
                first_frame_time = datetime.now()
        else:
            first_frame_data = da.isel({time_dim: 0}).values
            first_frame_time = pd.to_datetime(da[time_dim].values[0])
        
        # Garantir formato 2D
        if len(first_frame_data.shape) != 2:
            st.error(f"Erro: Formato de dados inesperado. Shape: {first_frame_data.shape}")
            return None
        
        # Criar mapa de cores
        im = ax.pcolormesh(ds.longitude, ds.latitude, first_frame_data, 
                         cmap=colormap, vmin=vmin, vmax=vmax)
        
        # Adicionar barra de cores
        cbar = plt.colorbar(im, fraction=0.046, pad=0.04)
        cbar.set_label('AOD 550nm')
        
        # Adicionar t√≠tulo inicial
        title = ax.set_title(f'AOD 550nm em {city} - {first_frame_time}', fontsize=14)
        
        # Adicionar shape do munic√≠pio selecionado se dispon√≠vel
        if municipality_shape:
            try:
                if hasattr(municipality_shape, '__geo_interface__'):
                    ax.add_geometries([municipality_shape], crs=ccrs.PlateCarree(), 
                                    facecolor='none', edgecolor='red', linewidth=2, zorder=3)
                    
                # Adicionar r√≥tulo do munic√≠pio
                ax.text(lon_center, lat_center, city, fontsize=12, fontweight='bold', 
                       ha='center', va='center', color='red',
                       bbox=dict(facecolor='white', alpha=0.7, boxstyle='round'),
                       transform=ccrs.PlateCarree(), zorder=4)
            except Exception as e:
                st.warning(f"N√£o foi poss√≠vel desenhar o shape do munic√≠pio: {str(e)}")
        
        # Fun√ß√£o de anima√ß√£o
        def animate(i):
            try:
                # Selecionar frame de acordo com a estrutura dos dados
                frame_data = None
                frame_time = None
                
                if 'forecast_period' in da.dims and 'forecast_reference_time' in da.dims:
                    # Determinar √≠ndices v√°lidos
                    fp_idx = min(0, len(da.forecast_period)-1)
                    frt_idx = min(i, len(da.forecast_reference_time)-1)
                    
                    frame_data = da.isel(forecast_period=fp_idx, forecast_reference_time=frt_idx).values
                    frame_time = pd.to_datetime(ds.forecast_reference_time.values[frt_idx])
                else:
                    # Selecionar pelo √≠ndice na dimens√£o de tempo
                    t_idx = min(i, len(da[time_dim])-1)
                    frame_data = da.isel({time_dim: t_idx}).values
                    frame_time = pd.to_datetime(da[time_dim].values[t_idx])
                
                # Atualizar dados
                im.set_array(frame_data.ravel())
                
                # Atualizar t√≠tulo com timestamp
                title.set_text(f'AOD 550nm em {city} - {frame_time}')
                
                return [im, title]
            except Exception as e:
                st.error(f"Erro no frame {i}: {str(e)}")
                return [im, title]
        
        # Limitar n√∫mero de frames para evitar problemas
        actual_frames = min(frames, 20)  # M√°ximo de 20 frames
        
        # Criar anima√ß√£o
        ani = animation.FuncAnimation(fig, animate, frames=actual_frames, 
                                     interval=animation_speed, blit=True)
        
        # Salvar anima√ß√£o
        gif_filename = f'AOD550_{city}_{start_date}_to_{end_date}.gif'
        
        with st.spinner('üíæ Salvando anima√ß√£o...'):
            ani.save(gif_filename, writer=animation.PillowWriter(fps=2))
        
        plt.close(fig)

        # NOVO: Analisar dados para todas as cidades do MS
        top_pollution_cities = None
        with st.spinner("üîç Analisando todas as cidades do MS para alerta de polui√ß√£o..."):
            top_pollution_cities = analyze_all_cities(ds, aod_var, cities)
        
        return {
            'animation': gif_filename,
            'timeseries': df_timeseries,
            'forecast': df_forecast,
            'dataset': ds,
            'variable': aod_var,
            'top_pollution': top_pollution_cities  # Novo item no dicion√°rio de resultados
        }
    
    except Exception as e:
        st.error(f"‚ùå Erro ao processar os dados: {str(e)}")
        st.write("Detalhes da requisi√ß√£o:")
        st.write(request)
        return None

# Carregar shapefiles dos munic√≠pios do MS
with st.spinner("Carregando shapes dos munic√≠pios..."):
    ms_shapes = load_ms_municipalities()

# Sidebar para configura√ß√µes
st.sidebar.header("‚öôÔ∏è Configura√ß√µes")

# Sele√ß√£o de cidade com os shapes dispon√≠veis
available_cities = sorted(list(set(ms_shapes['NM_MUN'].tolist()).intersection(set(cities.keys()))))
if not available_cities:
    available_cities = list(cities.keys())  # Fallback para a lista original

city = st.sidebar.selectbox("Selecione o munic√≠pio", available_cities)
lat_center, lon_center = cities[city]

# Adicionar sele√ß√£o do m√©todo de previs√£o na sidebar
st.sidebar.header("üîÆ M√©todo de Previs√£o")
forecast_method = st.sidebar.selectbox(
    "Escolha o m√©todo:",
    ['ensemble', 'linear_regression', 'moving_average', 'exponential_smoothing', 
     'polynomial', 'seasonal', 'random_forest'],
    format_func=lambda x: {
        'ensemble': 'üéØ Ensemble (Recomendado)',
        'linear_regression': 'üìà Regress√£o Linear',
        'moving_average': 'üìä M√©dia M√≥vel',
        'exponential_smoothing': 'üåä Suaviza√ß√£o Exponencial',
        'polynomial': 'üìê Ajuste Polinomial',
        'seasonal': 'üîÑ Decomposi√ß√£o Sazonal',
        'random_forest': 'üå≥ Random Forest'
    }[x]
)

# Adicionar op√ß√£o para comparar m√©todos
compare_methods = st.sidebar.checkbox("üî¨ Comparar todos os m√©todos", value=False)

# Configura√ß√µes de data e hora
st.sidebar.subheader("Per√≠odo de An√°lise")
start_date = st.sidebar.date_input("Data de In√≠cio", datetime.today() - timedelta(days=2))
end_date = st.sidebar.date_input("Data Final", datetime.today() + timedelta(days=5))  # Estendido para 5 dias

all_hours = list(range(0, 24, 3))
start_hour = st.sidebar.selectbox("Hor√°rio Inicial", all_hours, format_func=lambda x: f"{x:02d}:00")
end_hour = st.sidebar.selectbox("Hor√°rio Final", all_hours, index=len(all_hours)-1, format_func=lambda x: f"{x:02d}:00")

# Op√ß√µes avan√ßadas
st.sidebar.subheader("Op√ß√µes Avan√ßadas")
with st.sidebar.expander("Configura√ß√µes da Visualiza√ß√£o"):
    map_width = st.slider("Largura do Mapa (graus)", 5, 20, 10)
    animation_speed = st.slider("Velocidade da Anima√ß√£o (ms)", 200, 1000, 500)
    colormap = st.selectbox("Paleta de Cores", 
                          ["YlOrRd", "viridis", "plasma", "inferno", "magma", "cividis"])

# Agora, vamos adicionar o bot√£o logo ap√≥s o texto introdut√≥rio
st.markdown("### üöÄ Iniciar An√°lise de AOD")
st.markdown("Clique no bot√£o abaixo para gerar an√°lise completa de AOD para todos os munic√≠pios de MS.")

# Bot√£o para iniciar an√°lise
if st.button("üéûÔ∏è Gerar An√°lise Completa", type="primary", use_container_width=True):
    try:
        # Executar an√°lise e obter resultados
        results = generate_aod_analysis()
        
        if results:
            # Layout com abas para diferentes visualiza√ß√µes
            tab1, tab2, tab3 = st.tabs(["üìä An√°lise do Munic√≠pio", "‚ö†Ô∏è Alerta de Polui√ß√£o para MS", "üó∫Ô∏è Mapa e Anima√ß√£o"])
            
            with tab3:
                st.subheader("üé¨ Anima√ß√£o de AOD 550nm")
                st.image(results['animation'], caption=f"AOD 550nm em {city} ({start_date} a {end_date})")
                
                # Adicionar op√ß√µes para baixar
                with open(results['animation'], "rb") as file:
                    btn = st.download_button(
                        label="‚¨áÔ∏è Baixar Anima√ß√£o (GIF)",
                        data=file,
                        file_name=f"AOD_{city}_{start_date}_to_{end_date}.gif",
                        mime="image/gif"
                    )
            
            with tab1:
                st.subheader("üìä S√©rie Temporal e Previs√£o")
                
                # Layout de duas colunas
                col1, col2 = st.columns([3, 2])
                
                with col1:
                    # Preparar dados para gr√°fico
                    df_combined = results['forecast']
                    
                    # Criar gr√°fico
                    fig, ax = plt.subplots(figsize=(10, 6))
                    
                    # Dados hist√≥ricos
                    hist_data = df_combined[df_combined['type'] == 'historical']
                    ax.plot(hist_data['time'], hist_data['aod'], 
                           marker='o', linestyle='-', color='blue', label='Observado')
                    
                    # Dados de previs√£o
                    forecast_data = df_combined[df_combined['type'] == 'forecast']
                    ax.plot(forecast_data['time'], forecast_data['aod'], 
                           marker='x', linestyle='--', color='red', label='Previs√£o')
                    
                    # Formatar eixos
                    ax.set_title(f'AOD 550nm em {city}: Valores Observados e Previstos', fontsize=14)
                    ax.set_xlabel('Data/Hora', fontsize=12)
                    ax.set_ylabel('AOD 550nm', fontsize=12)
                    
                    # Formatar datas no eixo x
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m %H:%M'))
                    plt.xticks(rotation=45)
                    
                    # Adicionar legenda e grade
                    ax.legend()
                    ax.grid(True, alpha=0.3)
                    
                    # Adicionar faixa de qualidade do ar
                    ax.axhspan(0, 0.1, alpha=0.2, color='green', label='Boa')
                    ax.axhspan(0.1, 0.2, alpha=0.2, color='yellow', label='Moderada')
                    ax.axhspan(0.2, 0.5, alpha=0.2, color='orange', label='Insalubre')
                    ax.axhspan(0.5, 2.0, alpha=0.2, color='red', label='Perigosa')
                    
                    plt.tight_layout()
                    st.pyplot(fig)
                
                with col2:
                    # Estat√≠sticas
                    st.subheader("üìà Estat√≠sticas de AOD")
                    
                    # Calcular estat√≠sticas
                    if not hist_data.empty:
                        curr_aod = hist_data['aod'].iloc[-1]
                        max_aod = hist_data['aod'].max()
                        mean_aod = hist_data['aod'].mean()
                        
                        # Categorizar qualidade do ar baseado no AOD
                        def aod_category(value):
                            if value < 0.1:
                                return "Boa", "green"
                            elif value < 0.2:
                                return "Moderada", "orange"
                            elif value < 0.5:
                                return "Insalubre para grupos sens√≠veis", "red"
                            else:
                                return "Perigosa", "darkred"
                        
                        current_cat, current_color = aod_category(curr_aod)
                        
                        # Mostrar m√©tricas
                        col_a, col_b, col_c = st.columns(3)
                        col_a.metric("AOD Atual", f"{curr_aod:.3f}")
                        col_b.metric("AOD M√°ximo", f"{max_aod:.3f}")
                        col_c.metric("AOD M√©dio", f"{mean_aod:.3f}")
                        
                        # Mostrar categoria da qualidade do ar
                        st.markdown(f"""
                        <div style="padding:10px; border-radius:5px; background-color:{current_color}; color:white; text-align:center; margin:10px 0;">
                        <h3 style="margin:0;">Qualidade do Ar: {current_cat}</h3>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Previs√£o para os pr√≥ximos dias
                        if not forecast_data.empty:
                            st.subheader("üîÆ Previs√£o para os pr√≥ximos dias")
                            
                            # Agrupar por dia
                            forecast_data['date'] = forecast_data['time'].dt.date
                            daily_forecast = forecast_data.groupby('date')['aod'].mean().reset_index()
                            
                            for i, row in daily_forecast.iterrows():
                                day_cat, day_color = aod_category(row['aod'])
                                st.markdown(f"""
                                <div style="padding:5px; border-radius:3px; background-color:{day_color}; color:white; margin:2px 0;">
                                <b>{row['date'].strftime('%d/%m/%Y')}:</b> AOD m√©dio previsto: {row['aod']:.3f} - {day_cat}
                                </div>
                                """, unsafe_allow_html=True)
                    
                    # Exportar dados
                    st.subheader("üíæ Exportar Dados")
                    csv = df_combined.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="‚¨áÔ∏è Baixar Dados (CSV)",
                        data=csv,
                        file_name=f"AOD_data_{city}_{start_date}_to_{end_date}.csv",
                        mime="text/csv",
                    )
            
            # NOVA ABA: Alerta de Polui√ß√£o para MS
            with tab2:
                st.subheader("‚ö†Ô∏è Alerta de Polui√ß√£o para Munic√≠pios de MS")
                
                # Verificar se temos os dados de todas as cidades
                if 'top_pollution' in results and not results['top_pollution'].empty:
                    top_cities = results['top_pollution'].head(20)  # Pegar as 20 primeiras
                    
                    # Criar uma tabela formatada e colorida com as cidades mais cr√≠ticas
                    st.markdown("### üî¥ Top 20 Munic√≠pios com Maior Previs√£o de AOD")
                    
                    # Adicionar legenda de cores
                    st.markdown("""
                    <div style="display: flex; gap: 10px; margin-bottom: 15px;">
                        <div style="display: flex; align-items: center;">
                            <div style="width: 20px; height: 20px; background-color: darkred; margin-right: 5px;"></div>
                            <span>AOD ‚â• 0.5 (Muito Alto)</span>
                        </div>
                        <div style="display: flex; align-items: center;">
                            <div style="width: 20px; height: 20px; background-color: red; margin-right: 5px;"></div>
                            <span>AOD ‚â• 0.2 (Alto)</span>
                        </div>
                        <div style="display: flex; align-items: center;">
                            <div style="width: 20px; height: 20px; background-color: orange; margin-right: 5px;"></div>
                            <span>AOD ‚â• 0.1 (Moderado)</span>
                        </div>
                        <div style="display: flex; align-items: center;">
                            <div style="width: 20px; height: 20px; background-color: green; margin-right: 5px;"></div>
                            <span>AOD < 0.1 (Baixo)</span>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Renomear colunas para exibi√ß√£o
                    top_cities_display = top_cities.rename(columns={
                        'cidade': 'Munic√≠pio', 
                        'aod_max': 'AOD M√°ximo', 
                        'data_max': 'Data do Pico',
                        'nivel': 'N√≠vel de Alerta'
                    })
                    
                    # Fun√ß√£o para colorir as linhas baseado no valor de AOD
                    def highlight_aod(val):
                        try:
                            aod = float(val['AOD M√°ximo'])
                            if aod >= 0.5:
                                return ['background-color: darkred; color: white'] * len(val)
                            elif aod >= 0.2:
                                return ['background-color: red; color: white'] * len(val)
                            elif aod >= 0.1:
                                return ['background-color: orange; color: black'] * len(val)
                            else:
                                return ['background-color: green; color: white'] * len(val)
                        except:
                            return [''] * len(val)
                    
                    # Exibir tabela formatada
                    st.dataframe(
                        top_cities_display.style.apply(highlight_aod, axis=1),
                        use_container_width=True
                    )
                    
                    # Adicionar um aviso se houver cidades com n√≠vel alto ou muito alto
                    high_risk_cities = top_cities[top_cities['aod_max'] >= 0.2]
                    
                    if not high_risk_cities.empty:
                        st.warning(f"""
                        ### ‚ö†Ô∏è ALERTA DE POLUI√á√ÉO ATMOSF√âRICA
                        
                        Detectamos previs√£o de n√≠veis elevados de AOD (‚â• 0.2) para {len(high_risk_cities)} munic√≠pios nos pr√≥ximos 5 dias!
                        
                        Os munic√≠pios mais cr√≠ticos s√£o:
                        - **{high_risk_cities.iloc[0]['cidade']}**: AOD {high_risk_cities.iloc[0]['aod_max']:.3f} em {high_risk_cities.iloc[0]['data_max']}
                        - **{high_risk_cities.iloc[1]['cidade'] if len(high_risk_cities) > 1 else ''}**: AOD {high_risk_cities.iloc[1]['aod_max']:.3f if len(high_risk_cities) > 1 else 0} em {high_risk_cities.iloc[1]['data_max'] if len(high_risk_cities) > 1 else ''}
                        - **{high_risk_cities.iloc[2]['cidade'] if len(high_risk_cities) > 2 else ''}**: AOD {high_risk_cities.iloc[2]['aod_max']:.3f if len(high_risk_cities) > 2 else 0} em {high_risk_cities.iloc[2]['data_max'] if len(high_risk_cities) > 2 else ''}
                        
                        Recomenda-se aten√ß√£o especial a pessoas com problemas respirat√≥rios nestas localidades.
                        """)
                    
                    # Exportar dados da tabela
                    csv_top_cities = top_cities.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="‚¨áÔ∏è Baixar Tabela de Alerta (CSV)",
                        data=csv_top_cities,
                        file_name=f"AOD_alerta_MS_{start_date}_to_{end_date}.csv",
                        mime="text/csv",
                    )
                    
                    # Criar gr√°fico de barras com as 10 cidades mais cr√≠ticas
                    st.subheader("üìä Previs√£o de AOD M√°ximo - Top 10 Munic√≠pios")
                    
                    fig, ax = plt.subplots(figsize=(12, 6))
                    
                    # Selecionar top 10
                    top10 = top_cities.head(10)
                    
                    # Criar barras com cores baseadas no n√≠vel de AOD
                    colors = []
                    for aod in top10['aod_max']:
                        if aod >= 0.5:
                            colors.append('darkred')
                        elif aod >= 0.2:
                            colors.append('red')
                        elif aod >= 0.1:
                            colors.append('orange')
                        else:
                            colors.append('green')
                    
                    # Plotar gr√°fico
                    bars = ax.bar(top10['cidade'], top10['aod_max'], color=colors)
                    
                    # Adicionar r√≥tulos
                    for bar in bars:
                        height = bar.get_height()
                        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                                f'{height:.3f}', ha='center', va='bottom', 
                                fontsize=10, rotation=0)
                    
                    # Formata√ß√£o do gr√°fico
                    ax.set_title('Top 10 Munic√≠pios com Maior Previs√£o de AOD', fontsize=14)
                    ax.set_xlabel('Munic√≠pio', fontsize=12)
                    ax.set_ylabel('AOD M√°ximo Previsto', fontsize=12)
                    ax.set_ylim(0, max(top10['aod_max']) * 1.2)  # Ajustar limite do eixo Y
                    ax.axhline(y=0.5, linestyle='--', color='darkred', alpha=0.7)
                    ax.axhline(y=0.2, linestyle='--', color='red', alpha=0.7)
                    ax.axhline(y=0.1, linestyle='--', color='orange', alpha=0.7)
                    plt.xticks(rotation=45, ha='right')
                    plt.tight_layout()
                    
                    st.pyplot(fig)
                else:
                    st.error("‚ùå N√£o foi poss√≠vel obter dados de previs√£o para os munic√≠pios de MS.")
                    st.info("Tente novamente com um per√≠odo diferente ou verifique a conex√£o com a API do CAMS.")
    except Exception as e:
        st.error(f"‚ùå Ocorreu um erro ao gerar a an√°lise: {str(e)}")
        st.write("Por favor, verifique os par√¢metros e tente novamente.")

# Adicionar informa√ß√µes na parte inferior
st.markdown("---")
st.markdown("""
### ‚ÑπÔ∏è Sobre os dados
- **Fonte**: Copernicus Atmosphere Monitoring Service (CAMS)
- **Vari√°vel**: Profundidade √ìptica de Aeross√≥is (AOD) a 550nm
- **Resolu√ß√£o temporal**: 3 horas
- **Atualiza√ß√£o**: Di√°ria
- **Previs√£o**: At√© 5 dias √† frente

### üìñ Como interpretar:
- **AOD < 0.1**: Qualidade do ar boa
- **AOD 0.1-0.2**: Qualidade do ar moderada
- **AOD 0.2-0.5**: Insalubre para grupos sens√≠veis
- **AOD > 0.5**: Qualidade do ar perigosa

### üîç Novas funcionalidades:
- **Alerta de Polui√ß√£o**: Monitoramento autom√°tico dos 79 munic√≠pios de MS
- **Previs√£o de 5 dias**: An√°lise de tend√™ncias e picos de AOD
- **Top 20 Munic√≠pios**: Identifica√ß√£o das √°reas mais cr√≠ticas

Desenvolvido para monitoramento de aeross√≥is no estado de Mato Grosso do Sul - Brasil.
""")
